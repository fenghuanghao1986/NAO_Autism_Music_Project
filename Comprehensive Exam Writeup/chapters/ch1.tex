\chapter{Introduction}



\section{Autism Spectrum Disorders (ASD)}
Autism is a general term used to describe a spectrum of complex developmental
brain disorders causing qualitative impairments in social interaction and results in
repetitive and stereotyped behaviors. Currently one in every 88 children in the United
States are diagnosed with ASD and government statistics suggest the prevalence rate of
ASD is increasing 10-17 percent annually \cite{Fetch2002}. Children with ASD experience deficits in
appropriate verbal and nonverbal communication skills including motor control, emotional
facial expressions, and eye gaze attention \cite{RobotPlaymate2002}. Currently, clinical work such as Applied
Behavior Analysis (ABA) \cite{RollingRobot2002, MobileRobotic2002} has focused on teaching individuals with ASD
appropriate social skills in an effort to make them more successful in social situations \cite{Behavioral1964}.
With the concern of the growing number of children diagnosed with ASD, there is a high
demand for finding alternative solutions such as innovative computer technologies and/or
robotics to facilitate autism therapy. Therefore, research into how to design and use modern
technology that would result in clinically robust methodologies for autism intervention is
vital.
In social human interaction, non-verbal facial behaviors (e.g. facial expressions,
gaze direction, and head pose orientation, etc.) convey important information between
individuals. For instance, during an interactive conversation, the peer may regulate their
facial activities and gaze directions actively to indicate the interests or boredom. However,
the majority of individuals with ASD show the lack of exploiting and understanding these
cues to communicate with others. These limiting factors have made crucial difficulties for
individuals with ASD to illustrate their emotions, feelings and also interact with other
human beings. Studies have shown that individuals with autism are much interested to
interact with machines (e.g. computers, iPad, robots, etc.) than humans \cite{SocialInteract2003}. In this regard,
in the last decade several studies have been conducted to employ machines in therapy
sessions and examine the behavioral responses of people with autism. These studies have
assisted researchers to better understand, model and improve the social skills of individuals
on the autism spectrum.
This thesis presents the methodology and results of a study that aimed to design a
humanoid-robot therapy sessions for capturing, modeling and enhancing the social skills
of children with Autism. In particular we mainly focus on gaze direction and joint attention
modeling and analysis and investigate how the ASD and Typically Developing (TD)
children employ their gaze for interacting with the robot. In the following section, we have
a brief introduction of the existing assistive robots in the following section and how they
have been used in autism applications.

\section{Socially Assistive Robotics}
Socially Assistive Robotics (SAR) can be considered as the intersection of Assistive
Robotics (AR) and Socially Interactive Robotics (SIR), which has referred to robots that
assist human with physical deficits and also can provide certain terms of social interaction
abilities \cite{DefineSocial2005}. SAR contains all properties of SIR described in \cite{SocialInteract2003}, and also a few additional
attributes such as: 1) user populations (different groups of users, i.e. elders; individuals
with physical impairments; kids diagnosed with ASD; students); 2) social skills (i.e. speech
ability; gestures movement); 3) objective tasks (i.e. tutoring; physical therapy; daily life
assistance); 4) role of the robot (depends on the task the robot has been assigned for) \cite{DefineSocial2005}.
Companion robots \cite{AnalysisFactor2002} is one type of SAR that are widely used for elderly people
for health care supports. Research shows that this type of social robots can reduce stress
and depression of individuals in elderly stage \cite{AnimalAssist2002}. Service social robots are able to
accomplish a variety of tasks for individuals with physical impairments \cite{Fetch2002}. Studies have
shown that SAR can be used in therapy sessions for those individuals who suffer from
cognitive and behavioral disorders (e.g. Autism). SAR provides an efficient helpful
medium to teach certain types of skills to these groups of individuals \cite{RobotPlaymate2002, RollingRobot2002, MobileRobotic2002}.
Nowadays, there are very few companies that have been designing and producing
socially assistive robots. The majority of existing SARs are not commercialized yet and
because of being expensive and not well-designed user interfaces, they are mostly used forthe research purposes. Honda, Aldebaran Robotics and Hanson Robokind are the top
leading companies that are currently producing humanoid robots.
Ideally socially assistive robots can have fully automated systems to detect and
express social behaviors while interacting with humans. Some of the existing robot-human
interfaces are semi-autonomous and they can recognize some basic biometrics (e.g. visual
and audio commands of the user) and behavioral response. Besides, the majority of existing
robots are very complicated to work with. Therefore in the last couple of years several
companies have started to make these robots more user-friendly and responsive to both the
user need and the potential caregiver commands \cite{DefineSocial2005}.
Intelligent SARs aim to have the capability to recognize visual or audio commands,
objects, and specific human gestures. Some of these robots have the ability of detect human
face or basic facial expressions. For instance, ASIMO, a robot developed by Honda, it has
a sensor for detecting the movements of multiple objects by using visual information
captured from two cameras on its head. Plus its “eyes” can measure the distance of the
objects from the robot \cite{ASIMO2011}. Another example is from Aldebaran Robotics which designs
small size humanoid robots, called NAO. NAO robot has two cameras attached that are
used to capture single images and video sequences. This capturing module enables NAO
to see the different sides of an object and recognize it for future use. Furthermore, NAO
has a remarkable capability of recognizing faces and detecting moving objects.
Both of the aforementioned robots have speech recognition system. They can interpret
voice commands to accomplish a certain set of tasks which have been pre-programmed in
the system. NAO is able to identify words for running specific commands. However
ASIMO is able to distinguish between voices and other sounds. This feature empowers
ASIMO to perceive the direction of human’s speaker or recognize other companion robots
by tracking their voice \cite{DSMIV2000}. These robots can also speak in many different languages. For
example, NAO can speak in English, French, Chinese, Japanese and other languages up to
more than ten languages. This feature gives the robot a great social communication
functionality to interact with humans from all over the world.

\subsection{Socially Assistive Robots for Autism Therapy}
Socially assistive robots are emerging technologies in the field of robotics that aim
to utilize social robots to increase engagement of users as communicating with robots, and
elicit novel social behaviors through their interaction. One of the goal in SAR is to use
social robots either individually or in conjunction with caregivers to improve social skills
of individuals who have social behavioral deficits. One of the early applications of SAR is
autism rehabilitation. As mentioned before, autism is a spectrum of complex
developmental brain disorders causing qualitative impairments in social interaction.
Children with ASD experience deficits in appropriate verbal and nonverbal communication
skills including motor control, emotional facial expressions, and gaze regulation. These
skill deficits often pose problems in the individual’s ability to establish and maintain social
relationships and may lead to anxiety surrounding social contexts and behaviors \cite{Behavioral1964}.
Unfortunately there is no single accepted intervention, treatment, or known cure for
individuals with ASD.
Recent research suggests that children with autism exhibit certain positive social
behaviors when interacting with robots compared to their peers that do not interact with
robots \cite{RobotMovement, EnhanceEmpiri2011, DOMER2011, DefineSocial2005, SocialInteract2003}. These positive behaviors include showing emotional facial
expressions (e.g., smiling), gesture imitation, and eye gaze attention. Studies show that
these behaviors are rare in children with autism but evidence suggests that robots trigger
children to demonstrate such behaviors. These investigations propose that interaction with
robots may be a promising approach for rehabilitation of children with ASD.
There are several research groups that investigated the response of children with
autism to both humanoid robots and non-humanoid toy-like robots in the hope that these
systems will be useful for understanding affective, communicative, and social differences
seen in individuals with ASD (see Diehl et al., \cite{SocialInteract2003}), and to utilize robotic systems to develop
novel interventions and enhance existing treatments for children with ASD \cite{ASIMO2011, DSMIV2000, DoesMatter2006}.
Mazzei et al. \cite{ToInteract2004}, for example, designed the robot “FACE” to realistically show the details
of human facial expressions. A combination of hardware, wearable devices, and software
algorithms measured subject’s affective states (e.g., eye gaze attention, facial expressions,vital signals, skin temperature and EDA signals), were used for controlling the robot
reactions and responses.
Reviewing the literature in SAR \cite{DefineSocial2005, SocialInteract2003} shows that there are surprisingly very few
studies that used an autonomous robot to model, teach or practice the social skills of
individuals with autism. Amongst, teaching how to regulate eye-gaze attention, perceiving
and expressing emotional facial expressions are the most important ones. Designing robust
interactive games and employing a reliable social robot that can sense users’ socioemotional
behaviors and can respond to emotions through facial expressions or speech is
an interesting area of research. In addition, the therapeutic applications of social robots
impose conditions on the robot’s requirements, feedback model and user interface. In other
words, the robot that aims for autism therapy may not be directly used for depression
treatment and hence every SAR application requires its own attention, research, and
development
Only a few adaptive robot-based interaction settings have been designed and
employed for communication with children with ASD. Proximity-based closed-loop
robotic interaction \cite{LookApproach1972}, haptic interaction \cite{DiffEffect1966}, and adaptive game interactions based on
affective cues inferred from physiological signals \cite{SysObserv1968} are some of these studies. Although
all of these studies were conducted to analyze the functionality of robots for socially interacting with individuals with ASD, these paradigms were limitedly explored and
focused on their core deficits (i.e., Facial expression, eye gaze and joint attention skills).
Bekele and colleagues \cite{AutisticDist1943} studied the development and application of a humanoid
robotic system capable of intelligently administering joint attention prompts and adaptively
responding based on within system measurements of gaze and attention. They found out
that preschool children with ASD have more frequent eye contact toward the humanoid
robot agent, and also more accurate respond in joint attention stimulations. This suggests
that robotic systems have the enhancements for successfully improve the coordinated
attention in kids with ASD.
Considering the existing SAR system and the major social deficits that individuals
with autism may have, we have designed and conducted robot-based therapeutic sessions
that are focused on different aspects of social skills of children with autism. In this thesis
we employed NAO which can be remotely controlled to communicate with the children.
We conducted two different protocols to examine the social skills of children with autism
and provide feedbacks to improve their behavioral responses. The contribution of our work
has been introduced in Section 1.4 and the details of the game setting, experiments,
modeling and analysis are provided in Chapter 4.

\section{Music Therapy for ASD}

\section{Contributions}


\section{Orgizaition}


\section{Dissertation Outline}
This thesis is organized as follows: In Chapter two, we present
related work for facial features extraction, two dimensional (2-D),
three dimensional (3-D), and multi-modal (2-D + 3-D) face
recognition. Chapter three explains our algorithm for 2-D facial
feature extraction from frontal face images (i.e., Improved ASM) and
our algorithm for 3-D facial feature extraction (i.e., the
extraction of the three feature points) along with the experimental
results. Chapter four presents our approach for 3-D face modeling
and recognition based on ridge images. Chapter five describes our
multi-modal face modeling and recognition (2-D/3-D) based on
attributed relational graphs along with the experiments. In
addition, we present two fusion techniques for combining the 2-D and
3-D modalities in this chapter. Finally in Chapter six, we present
the conclusion and the future research directions.
