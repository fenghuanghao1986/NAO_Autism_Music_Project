\chapter{Related Works}

\section{Autism}
Individuals with autism spectrum disorder experience verbal and nonverbal
communication impairments, including motor control, emotional facial expressions, and
eye gaze attention. Oftentimes, individuals with high-functioning autism have deficits in
different areas, such as (1) language delay, (2) difficulty in having empathy with their peer
and understanding others emotions (i.e. facial expressions recognition.), and more
remarkably (3) joint attention (i.e. eye contact and eye gaze attention). Autism is a disorder
that appears in infancy \cite{Epidemiology1966}. Although there is no single accepted intervention, treatment,
or known cure for ASDs, these individual will have more successful treatment if ASD is
diagnosed in early stages. At the first glance at the individual with autism, you may not
notice anything odd, however after trying to talk to her/him, you will understand something
is definitely not right \cite{BrokenMirror2006}. S/He may not make eye contact with you and avoid your gaze
and fidget, rock her/his body and bang her/his head against the wall \cite{BrokenMirror2006}.
In early 1990s, researchers in the University of California at San Diego aimed to
find out the connections between autism and nervous system (i.e. mirror neurons). Mirror
neuron \cite{BrokenMirror2006} is a neuron that is activated either when a human acts an action or observes the
same action performed by others. As these neurons are involved with the abilities such as
empathy and perception of other individual’s intentions or emotions, they came up with 
malfunctioning of mirror neuron in individuals with ASD \cite{BrokenMirror2006}. There are several studies
that focus on the neurological deficits of individuals with autism and studying on their
brain activities. Figure 2-1 demonstrates the areas in the brain that causes the reduce mirror
neuron activities in individuals with autism.
Individuals with autism might also have several other unusual social developmental
behaviors that may appear in infancy or childhood. For instance children with autism show
less attention to social stimuli (e.g. facial expressions, joint attention), and respond less
when calling their names. Compared with typically developing children, older children or
adults with autism can read facial expressions less effectively and recognize emotions
behind specific facial expressions or the tone of voice with difficulties \cite{LogicScien1959}. In contrast to
TD individuals, children with autism (i.e. high-functioning, Asperger syndrome) may be
overwhelmed with social signals such as facial behaviors and expression and complexity
of them and they suffer from interacting with other individuals, therefore they would prefer
to be alone. That is why it would be difficult for individuals with autism to maintain social
interaction with others \cite{InfantileAutism1975}.
In order to diagnose and asses the aspects and score the social skill level of an individual
with autism, several protocols are available. One of the commercially available protocols
is called Autism Diagnostic Observation Schedule (ADOS) \cite{AutismDiagno1989} that consists of four
modules and several structured tasks that are used to measure the social interaction levels
of the subject and examiner. We are inspired by ADOS in designing our intervention
protocols later described in Chapter 4. Hence, we briefly review ADOS in the next section.

\subsection{Turn-Taking}
Turn-taking is a type of organization in conversation and discourse where participants speak 
one at a time in alternating turns. In practice, it involves processes for constructing 
contributions, responding to previous comments, and transitioning to a different speaker, 
using a variety of linguistic and non-linguistic cues.\cite{BehaviorlaStudy1964}

While the structure is generally universal,\cite{RoboticMovement} that is, overlapping talk is generally 
avoided and silence between turns is minimized, turn-taking conventions vary by culture 
and community.\cite{EnhanceEmpiri2011} Conventions vary in many ways, such as how turns are distributed, how 
transitions are signaled, or how long is the average gap between turns.

In many contexts, conversation turns are a valuable means to participate in social life 
and have been subject to competition.\cite{DOMER2011} It is often thought that turn-taking strategies 
differ by gender; consequently, turn-taking has been a topic of intense examination in 
gender studies. While early studies supported gendered stereotypes, such as men interrupting
more than women and women talking more than men,\cite{DefineSocial2005} recent research has found mixed evidence 
of gender-specific conversational strategies, and few overarching patterns have emerged.\cite{SocialInteract2003}

https://en.wikipedia.org/wiki/Turn-taking

\subsection{Emotion EDA}
Emotion is an intense mental experience often manifested by rapid heartbeat, breathing, 
sweating, and facial expressions. Emotion recognition from these physiological signals 
is a challenging problem with interesting applications such as developing wearable 
assistive devices and smart human-computer interfaces. This paper presents an automated 
method for emotion classification in children using electrodermal activity (EDA) signals. 
The time-frequency analysis of the acquired raw EDAs provides a feature space based on 
which different emotions can be recognized. To this end, the complex Morlet (C-Morlet) 
wavelet function is applied on the recorded EDA signals. The dataset used in this paper 
includes a set of multimodal recordings of social and communicative behavior as well 
as EDA recordings of 100 children younger than 30 months old. The dataset is annotated 
by two experts to extract the time sequence corresponding to three main emotions 
including “Joy”, “Boredom”, and “Acceptance”. The annotation process is performed 
considering the synchronicity between the children's facial expressions and the EDA 
time sequences. Various experiments are conducted on the annotated EDA signals to 
classify emotions using a support vector machine (SVM) classifier. The quantitative 
results show that the emotion classification performance remarkably improves compared 
to other methods when the proposed wavelet-based features are used.

Physiological responses have been identified as reliable indicators of human emotional 
and cognitive states. This section is dedicated to review some existing methods used for 
human emotion recognition based on various physiological responses, such as facial 
expression and other types of bio-signals.    
A wearable glass device was designed by \cite{WearableDevice2016} to measure both electrodermal 
activity (EDA) and photoplethysmogram data for emotion recognition purposes. A built-in 
camera was also used in this device for capturing partial facial expression from the eye 
and nose area. This approach obtains remarkable performance in facial expression 
recognition in the subject-dependent cases. However, for subject-independent cases, 
it results in different accuracies across different types of emotions, which is an 
undesirable feature. 
EDA has been used as an effective and reproducible electrophysiological method for 
investigating sympathetic nervous system function \cite{WearableDevice2016, AssociationBetween2013, SympatheticSkin1984, PrincipalComponent2000}. Note that the sympathetic nervous 
burst changes the skin conductance, which can be traced by analyzing the EDA signals\cite{SkinConduct2006, SympatheticSkin1981, DecodeChild2013}. The Q-sensor 
is a convenient wireless-based EDA device with no need for cables, boxes, or skin 
preparation. This device can track three types of data including EDA, temperature, 
and acceleration at the same time \cite{Validation2013}. It is worth mentioning that 
as of today, there has been no published work on emotion classification using the 
EDA signals collected by this dataset collected at the Georgia Institute of 
Technology \cite{DecodeChild2013}.
Several emotion classification methods have been presented in the literature using 
different bio-signals \cite{EmotionInten2014, EmotionResp2013, ElectAct2000, HeteroKnow2016}. Due to the variety of the signals used in these methods, 
different approaches have been designed to comply with their specific characteristics. 
Analysis of variance (ANOVA) and linear regression \cite{ElectAct2000} are the 
commonly used methods to extract features from bio-signals and to recognize different 
emotional states. These methods are based on the assumption of a linear relationship 
between the recorded signals and emotional states. A fuzzy-based classification 
method \cite{EmotionInten2014} has been used in to transform EDA and facial 
electromyography (EMG) to valence and arousal states. These states were then used 
to classify different emotions. 
Artificial neural networks (ANN) have also been applied for emotion classification 
tasks based on physiological responses. \cite{MultPercep2007} developed a multilayer perceptron 
network (MLP) architecture capable of recognizing five emotions using various features 
from Electrocardiography (ECG) and EDA signals, and obtained very accurate classification 
performance. \cite{EmotionRecog2004} employed K-nearest neighborhood and discriminant 
function analysis to perform the emotion classification task using different features 
extracted from the EDA signals, body temperature and heart rate.
Support Vector Machine (SVM) is a well-known supervised learning algorithm that has 
extensively been used for pattern classification and regression \cite{SupportVector1995}. The SVM classifier tends to separate dataset by drawing an optimal hyperplane 
between classes such that the margin between them becomes maximum. The samples of 
each class that are located within the margin are called support vectors and play the 
main role in calculating the parameters of the hyperplanes between the corresponding 
classes. Machine learning algorithms such as SVM, linear discriminant analysis (LDA), 
and classification and regression tree (CART) have been employed for emotion 
classification purposes. For instance, in several works including \cite{Taxonomy2011, EmotionClassifi2014}, the authors combined various types of bio-signals such as ECG, 
skin temperature (SKT), HR, and Photoplethysmogram (PPG) for  emotion classification 
purposes. \cite{FeatureSelection2006} proposed unsupervised clustering methods for emotion 
recognition. Their method benefited from several features obtained from different 
body responses such as SC, HR, and EMG. They showed that only a few statistical 
features such as the mean and standard deviation of the data can be relevant identifiers 
for defining different clusters. 
EDA signals are nonstationary and noisy; hence, wavelet-based analysis of EDA signals 
has been considered in the literature \cite{EmotionalState2013, EMGGSR2009}
either as a pre-processing step or a feature extraction approach for emotion classification. 
\cite{EmotionalState2013} used a set of wavelet coefficients representing EDA features 
together with heart rate signal to increase the percentage of correct classifications 
of emotional states and provide clearer relationships among the physiological response 
and arousal and valence. \cite{EDA2016} used a feature space based on the 
discrete wavelet transform (DWT) of the EDA signal to distinguish subjects suffering 
social anxiety disorder (SAD) and a control group. Using MLP and DWT features, they 
achieved a classification accuracy of ~85%.
To the best of our knowledge there are a few works \cite{EmotionResp2013, SlowEcho2009} that have studied and compared different automated 
classification techniques for emotion recognition of children using EDA signals. 
This motivated us to conduct this study using an existing dataset, which concentrates 
on emotion classification of children based on the relationship between their facial 
expressions and the collected EDA signals.


\subsection{Motor control}
Motor control is the systematic regulation of movement in organisms that possess 
a nervous system. Motor control includes movement functions which can be attributed 
to reflex,\cite{BehaviorlaStudy1964}. Motor control as a field of study is primarily a sub-discipline of 
psychology or neurology.

Recent psychological theories of motor control present it as a process by which 
humans and animals use their brain/cognition to activate and coordinate the muscles 
and limbs involved in the performance of a motor skill. From this mixed psychological 
perspective, motor control is fundamentally the integration of sensory information, 
both about the world and the current state of the body, to determine the appropriate 
set of muscle forces and joint activations to generate some desired movement or action. 
This process requires cooperative interaction between the central nervous system and 
the musculoskeletal system, and is thus a problem of information processing, 
coordination, mechanics, physics, and cognition.\cite{RoboticMovement, EnhanceEmpiri2011} Successful motor control 
is crucial to interacting with the world, not only determining action capabilities, 
but regulating balance and stability as well.

The organization and production of movement is a complex problem, so the study of 
motor control has been approached from a wide range of disciplines, including 
psychology, cognitive science, biomechanics and neuroscience. While the modern 
study of motor control is an increasingly interdisciplinary field, research 
questions have historically been defined as either physiological or psychological, 
depending on whether the focus is on physical and biological properties, or 
organizational and structural rules.\cite{DOMER2011} Areas of study related to motor control 
are motor coordination, motor learning, signal processing, and perceptual control 
theory.
%https://en.wikipedia.org/wiki/Motor_control


\section{ADOS}
The Autism Diagnostic Observation Schedule (ADOS) is a standardized protocol
for observing the social and communicative behaviors associated with autism. Eight tasks
have contained in ADOS, as shown in the table below. 20-30 minutes are required for an
examiner to complete the entire tasks \cite{AutismDiagno1989}.
As shown in TABLE 2-1, each task contains one or few aspects of social skills
including turn taking (refers to the process by which people in a conversation decide who
is to speak next), joint attention, reading emotions etc. Right after the interview, examiner
would provide a general ratings based on the observation in all the tasks which have been
targeted to code.
ADOS contains four modules that are designed for specific age range and set of social
developmental abilities. Examiner may use ‘Module 1’ if the child uses a little or no phrase
speech however if s/he utilizes phrase speech but do not speak fluently ‘Module 2’ may be
employed. Some examples of Modules 1 or 2 are responding to name, social smile, and
bubble play. ‘Module 3’ is used for younger children who are verbally fluent and ‘Module
4’ is employed for adolescents and adults with fluent verbal skills. Modules 3 or 4 can
include communication, and exhibition of empathy or comments on others' emotions.
Considering these four modules, ADOS can provide scores regarding these four areas (1)
Reciprocal social interaction, (2) Communication/language, (3) Stereotyped/restricted
behaviors, and (4) Mood and non-specific abnormal behaviors. In our study we employed
ADOS and some tasks described in it for introducing new robot-based games and social
interaction to children that will be explained in Chapter 4 section 2.3.



