\chapter{Protocol 1: Acoustic Music Teaching Experiment Design Data Acquisition and Result}
Few questions will be answered in terms of social skills in this chapter:
1) Turn Taking: How well kids with autism behave during the teaching and learning
process compare to TD group, e.g., kid listen to the instruction or demonstration 
from robot before plays instrument;
2) Joint Attention and Eye-Gaze Attention: How well kids with ASD follow instructions 
and adapt hints compare to TD kids, e.g., kid follows hitting positions demonstrated 
by robot or follows the change of eye colors;
3) Motor Control: How well ASD kids play the xylophone in terms of volume, pitch and
accuracy compare to TD group, e.g., a good multiple strikes should be recognized by 
STFT as a sequence of frequencies that designed from previous chapter;
4) Engagement and Event Based Emotion: How kids engage to different music teaching
events and what are the emotions during certain events, e.g., using EDA signal to
find out the emotions regarding different situations for example having hard time
memorizing a sequence of notes;
5) Facial Expression and Emotions Correlation: (will not be presented in this version);
6) Music Emotions and Feelings: How kids perceive emotions in small pieces of music 
within different melodies, e.g., music in different keys.\\

\section{Room Setup and Participants}
% describe and show the room orgnization and describer subjects' detail here

\section{Experiment Design}
In order to collect all the data for answering the questions above, a set of
intervention sessions has designed using music therapy concept. 6 - 7 sessions
has settled for ASD group and 2 sessions for TD group. For ASD group, entire
sessions have been divided into 3 parts: baseline session, intervention sessions
and exit session. Similar to ASD group, TD group only includes baseline session
and exit session for comparison purpose. In addition, a social music
game play has also included in each session for system testing and entertainment
purpose.\\

\subparagraph{Baseline Session: }Participants has been asked to follow all the 
instructions contains all the practices from the following intervention sessions. 
Including single bar strike, multiple bars strike, half song play and the whole
song play. We choose a very popular kid's song "Twinkle Twinkle Little Star" 
for this specific session due to the well known of this song in almost 
everyone's childhood.\\

\subparagraph{Intervention Sessions: }These sessions are assigned to ASD group
particularly. Including single strike with color hints, multiple strikes with
colors hint, half-song practice and whole song practice. In this part, a special
participant selected song will be used through the rest of the sessions. In the second
half of this intervention session set, single/multiple strikes has also covered
before the half/full song practice in order to have participants to use the
color matching technique during the high level music play due to lack of professional
music background knowledge. In addition, starting from session 2, a single strike
warm up practice has added before the formal music practice starts. This particular
practice has designed for having better motor control for ASD group, that allows
the robot to recognize notes properly and also deliver the concept in telling the
difference between "make a sound" and "play a musical note". \\

\subparagraph{Exit Session: }Both groups has assigned to go through the same steps
as the baseline session in choice of their own songs. We would like to see the 
difference between two groups in learning a beloved song by their own.\\

Due to the difficulty of customized songs, the total session numbers can be
various, 6 visits will be the minimum and cannot go beyond 8 times. More detailed 
experiment design is shown in the table below:\\

% show all experiment setup table here

\section{Methodology and Experiment Result}

\subsection{Social Aspects Annotation and Coding Methods}
This part is to describe how to do video coding in these social features.
Basically just post process by watching the front face videos and by listen to the
audio to code how the social behaviors been performed. Have to copy some of the stuff
from previous studies.
\subparagraph{Turn-Taking Coding}
\subparagraph{Joint/Eye-gaze Attention Coding}

\subsection{Motor Control Scoring System}
This is related to hitting practice and play practice in real time during the session.
Need to have connections with the module 2 real time performance scoring feedback system.
Describe the how the flow goes during the session and how to have small add on dosage
if the accuracy not good. 
Also have to make up a story when it goes to the half/whole song, how to manage that
if the kid cannot play well, just cut the whole chunk into small continuous pieces
and use the same methods and scoring system to deliver the idea.

\subsection{Emotion Detection}
In this section, have to include more of my journal paper material here. Including 
methods and valance thing here. Just copy and paste first for now. 


\subsection{Dialog System}

\subsubsection{Speech Recognition}
http://doc.aldebaran.com/2-1/naoqi/audio/alspeechrecognition.html

\subsubsection{Dynamic Oral Feedback}
reason to design the dynamic feedback. 

\