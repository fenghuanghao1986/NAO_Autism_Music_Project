\chapter{Related Works}

\section{Autism}
Individuals with autism spectrum disorder experience verbal and nonverbal
communication impairments, including motor control, emotional facial expressions, and
eye gaze attention. Oftentimes, individuals with high-functioning autism have deficits in
different areas, such as (1) language delay, (2) difficulty in having empathy with their peer
and understanding others emotions (i.e. facial expressions recognition.), and more
remarkably (3) joint attention (i.e. eye contact and eye gaze attention). Autism is a disorder
that appears in infancy \cite{Epidemiology1966}. Although there is no single accepted intervention, treatment,
or known cure for ASDs, these individual will have more successful treatment if ASD is
diagnosed in early stages. At the first glance at the individual with autism, you may not
notice anything odd, however after trying to talk to her/him, you will understand something
is definitely not right \cite{BrokenMirror2006}. S/He may not make eye contact with you and avoid your gaze
and fidget, rock her/his body and bang her/his head against the wall \cite{BrokenMirror2006}.
In early 1990s, researchers in the University of California at San Diego aimed to
find out the connections between autism and nervous system (i.e. mirror neurons). Mirror
neuron \cite{BrokenMirror2006} is a neuron that is activated either when a human acts an action or observes the
same action performed by others. As these neurons are involved with the abilities such as
empathy and perception of other individual’s intentions or emotions, they came up with 
malfunctioning of mirror neuron in individuals with ASD \cite{BrokenMirror2006}. There are several studies
that focus on the neurological deficits of individuals with autism and studying on their
brain activities. Figure 2-1 demonstrates the areas in the brain that causes the reduce mirror
neuron activities in individuals with autism.\\

Individuals with autism might also have several other unusual social developmental
behaviors that may appear in infancy or childhood. For instance children with autism show
less attention to social stimuli (e.g. facial expressions, joint attention), and respond less
when calling their names. Compared with typically developing children, older children or
adults with autism can read facial expressions less effectively and recognize emotions
behind specific facial expressions or the tone of voice with difficulties \cite{LogicScien1959}. In contrast to
TD individuals, children with autism (i.e. high-functioning, Asperger syndrome) may be
overwhelmed with social signals such as facial behaviors and expression and complexity
of them and they suffer from interacting with other individuals, therefore they would prefer
to be alone. That is why it would be difficult for individuals with autism to maintain social
interaction with others \cite{InfantileAutism1975}.\\

In order to diagnose and asses the aspects and score the social skill level of an individual
with autism, several protocols are available. One of the commercially available protocols
is called Autism Diagnostic Observation Schedule (ADOS) \cite{AutismDiagno1989} that consists of four
modules and several structured tasks that are used to measure the social interaction levels
of the subject and examiner. We are inspired by ADOS in designing our intervention
protocols later described in Chapter 4. Hence, we briefly review ADOS in the next section.\\


\subsection{Turn-Taking}
Turn-taking is a type of organization in conversation and discourse where participants speak 
one at a time in alternating turns. In practice, it involves processes for constructing 
contributions, responding to previous comments, and transitioning to a different speaker, 
using a variety of linguistic and non-linguistic cues.\cite{BehaviorlaStudy1964}\\


While the structure is generally universal,\cite{RoboticMovement} that is, overlapping talk is generally 
avoided and silence between turns is minimized, turn-taking conventions vary by culture 
and community.\cite{EnhanceEmpiri2011} Conventions vary in many ways, such as how turns are distributed, how 
transitions are signaled, or how long is the average gap between turns.\\


In many contexts, conversation turns are a valuable means to participate in social life 
and have been subject to competition.\cite{DOMER2011} It is often thought that turn-taking strategies 
differ by gender; consequently, turn-taking has been a topic of intense examination in 
gender studies. While early studies supported gendered stereotypes, such as men interrupting
more than women and women talking more than men,\cite{DefineSocial2005} recent research has found mixed evidence 
of gender-specific conversational strategies, and few overarching patterns have emerged.\cite{SocialInteract2003}\\


%https://en.wikipedia.org/wiki/Turn-taking

\subsection{Motor control}
Motor control is the systematic regulation of movement in organisms that possess 
a nervous system. Motor control includes movement functions which can be attributed 
to reflex,\cite{BehaviorlaStudy1964}. Motor control as a field of study is primarily a sub-discipline of 
psychology or neurology.\\


Recent psychological theories of motor control present it as a process by which 
humans and animals use their brain/cognition to activate and coordinate the muscles 
and limbs involved in the performance of a motor skill. From this mixed psychological 
perspective, motor control is fundamentally the integration of sensory information, 
both about the world and the current state of the body, to determine the appropriate 
set of muscle forces and joint activations to generate some desired movement or action. 
This process requires cooperative interaction between the central nervous system and 
the musculoskeletal system, and is thus a problem of information processing, 
coordination, mechanics, physics, and cognition.\cite{RoboticMovement, EnhanceEmpiri2011} Successful motor control 
is crucial to interacting with the world, not only determining action capabilities, 
but regulating balance and stability as well.\\


The organization and production of movement is a complex problem, so the study of 
motor control has been approached from a wide range of disciplines, including 
psychology, cognitive science, biomechanics and neuroscience. While the modern 
study of motor control is an increasingly interdisciplinary field, research 
questions have historically been defined as either physiological or psychological, 
depending on whether the focus is on physical and biological properties, or 
organizational and structural rules.\cite{DOMER2011} Areas of study related to motor control 
are motor coordination, motor learning, signal processing, and perceptual control 
theory.\\

%https://en.wikipedia.org/wiki/Motor_control
\section{Human Robot Interaction in Autism}
Children with ASD experience deficits in appropriate verbal and non-verbal communication skills including motor control, emotional facial expressions, eye-gaze attention, and joint attention. Many studies have been conducted to identify therapeutic methods that can benefit children with ASD [52]. However, only a few groups used humanoid robots for teaching or practicing social communication skills [53, 54, 55, 56, 57, 58, and 59].
For some of the social behaviors, such as eye contact, joint attention, facial expressions recognition, that are rarely seen in interactions of children ASD, several evidence suggest that robots can trigger them more effectively than human [78]. Researchers observed that individuals with ASD have more interest toward a robot therapeutic partner than a human. In most cases participants showed better speech and movement imitation compared with response to a human partner [79]. Although a recent case study [52] which was done by Ricks (2010) suggests that this approach might have clinical utility, still this area is obviously in its infancy. Studies have shown that positive feedback from the robot on the participants’ performance is an effective way to encourage children with ASD to communicate more [52]. Other studies have also examined the use of affect recognition (e.g. emotional state, arousal level) based on psychophysiological responses to modify the behaviors during a robotic game. However, there is limited information on the utility of humanoid robots’ positive feedback in interventions for individuals with ASD.

\subsection{Interactive and Therapeutic Robots Designs for Autism}
Different types of robots have been used in autism research for various purposes. Some researchers have been attempting to utilize a realistic human appearance [56], while others have created robots with very mechanical forms [54], and others have developed robots with a cartoonish or animal form [58]. Generally speaking different categories of robot that have been used for autism research can be placed either into Non-Humanoid and Humanoid robots group [52], which will be explained in the following sections.

\subsubsection{Non-Humanoid Robots}
Non-humanoid robots are those robots which do not have the same body joint and facial appearance as human does. It contains those animal like, cartoonish, or non-human like appearances. These robots have been used by several researchers in the last two decades. This category of robots is generally easier to design and develop and less expensive, therefore, several of initial robot-human interaction for individuals with ASD was conducted by non-humanoid robots. The bubble-blowing robot at USC (while children approached it, the robot will node head make voice or blow bubble from lower part of robot body), for instance, was not a human form robot and can be built simply [53]. Another non-humanoid robot used by researchers from University of Hertfordshire called Labo-1 [54], which can play tag games (tip you’re it or tig), with children. (In the game, several children play with the robot together, the robot uses its heat sensor to approach kids as a type of interaction.) In Yale University, researchers were using a mobile robotic dinosaur named Pleo who can show emotions and desires by using its sounds and body movements [55]. Children in the clinic have been helped by Pleo’s pet-like appearance, expressiveness, and versatility.
The reason why researchers using non-humanoid robots is that they found out that when children with ASD see humans, they usually will choose to avoid and not to interact with them. On the contrary, an animal shape or toy shape robot would be easier for kids to engage with and have a better interaction.
\subsubsection{Humanoid Robots}

Humanoid robots generally provide the human-like appearance and consist of body parts such as humanoid head, body and arms. Advanced humanoid robot would be able to move different parts of it body to walk or dance (NAO), some of the humanoid robot also has the capability to show facial expressions (e.g. ZENO). This type of robot unlike non-humanoid robot, they have the ability to accomplish more complicated social communication tasks than non-humanoid robot, but those tasks will be less complicated than human-human interaction. This capability can help us to design interaction sessions and therapeutic sessions for children with autism and assist them with improving their social behaviors.
Robins from University of Hertfordshire, who is one of the pioneers which employed a study to evaluate the importance of robot’s appearance for autism research. A doll-like robot called Robota were asked to interact with children with autism [56]. This example shows that children appeared to be more interested in interaction with less-human like robots. Researchers conclude that children with ASD would prefer a simple non-complexity and less details of human but still hold the humanoid form. So, a robot called KASPAR has been developed by Robins to fit this design criteria [57].
Similar conclusions have been made by researchers at the National Institute of Information and Communications Technology (NIICT) in Japan. They found out that when kids with ASD have interaction with their designed robot called Infanoid, the children tend to pay more attention on the mechanical parts of the robot’s body than communicating with the robot itself [52]. A small soft snowman-shaped robot, called Keepon, was designed to represent as a simple, repeatable, mechanical robot regarding the reason mentioned above [58]. Keepon can express its emotions conveyed by shaking, rocking, and bobbing up and down which can be used as a super fun toy companion for kids with ASD. Another humanoid robot which has been designed by researchers at the University of Pisa, is known as FACE. The purpose of their project is to create a robot as realistic as possible to a human face for evaluating how human react as the FACE displays different expressions [59]. (During the sessions, child (IQ around 85) with autism did not show any interest in FACE at the beginning. However, with verbal suggestion, kid replied the expression by using a word “damsel” which is from a fairy tale, though the FACE showing a sad expression on it.) This study suggested that by using FACE, it is possible to extend emotional recognition skill to children with autism.
In the last few years several different types of non-humanoid and humanoid robots have been used for autism therapeutics sessions that we will discuss about them in the next session.
\subsection{Different Therapeutic approaches for Individuals with ASD}
As explained in Chapter 2, different individuals with autism might suffer from various types of social or developmental behavior. Therefore in order to have an effective therapeutic intervention setting we need to focus on various tasks and treatments. Bellow we will provide different intervention aspects that majority of children with ASD may suffer from.
\subsubsection{Self-Initiated Interactions}
The difficulty for initiating a social conversation or interaction is one of the impaired social skills of children with ASD. This problem may represent as difficulty for conveying what they want, and why they want it. For example, when a child in early age who wants to urinate, he might have to ask for parent’s help, rather than hold it there or let it be. Clinicians try to encourage those kids to ask to play certain toys and a reward will be given after they did it. Instead of human therapists, researcher extended this idea using robots to encourage the children to engage the robot proactively. The robot has built at USC [53] which has a large button on its back, and it was programmed to encourage social interaction with children. For example, the robot will nod its head and make a sound to encourage the kid to approach it; when the kid walk away, it will move its head down and make sad kind of sound to imply the child and ask him/her to come closer to the robot. If the child presses that button on the robot, it will blow bubbles and turn. In this study, one hundred minutes experiments have been recorded, three different conditions have been considered which are the time kids spent near 1) the wall;2) the parent; and 3) behind the robot. Kids have been separated in two groups: ‘Group A’ (children like the robot) and ‘Group B’ (children do not like the robot) total number of eight children with ASD. The result shows that the Group A spent more than 60\% of the time playing with the robot, and Group B spent more than 50\% of the time showing the negative reaction (i.e. go away from robot, play with himself) from avoiding the robot. This study might not be very convincing because it is totally free play with the robot; the experimental settings haven’t kept the same, and the limited numbers of participants. Also without control group like typically developing they could not compare the differences of ASD and TD children, within the robot games. However, it shows the capability of encourage children to communication with robot, and lead the conversation [53].
\subsubsection{Turn-Taking Activities}
At the University of Hertfordshire and the University of California, researchers have built small mobile robots that focused on helping children with ASD in turn-taking behaviors [54 and 53]. It is easily to found out that children with ASD have a hard time to allow their conversation partner to participate. The researchers try to use these robots to help them become accustomed to waiting for responses after they say or do something. Labo-1 built by the University of Hertfordshire, which can play a game called tag with children. This game will forces them to alternate between engaging and avoiding the robot [54].
Labo-1 is a mobile platform that has an AI system resembled in a sturdy flat-topped buggy. Children have been allowed to freely play with Labo-1 as a teacher was deciding about the how to switch between different games/sessions considering children appears (i.e. difference reactions of children like tired or less interested into robot). From their initial trials, children were in overall happy to play with robot. At the beginning of the game, the robot showed several simple behavior patterns, such as going forward and backward. Kids showed positive response to these behaviors and enjoy to keep playing with Labo-1. Children were also enjoyed interacting with the robot while it used a feature called ‘heat following behavior’, they moved away from the robot and see if the robot can follow or not. There were five trials in total, three of them lasted around four minutes, and the remaining two had duration of approximately fourteen minutes. Researchers realized that the issues that may cause this difference might be related to the levels of the children’s functioning. Since children are not in complete control the robot’s actions, and children’s response were totally different, some of them either walked or crawled around the room, some of them just simply lay on the floor to interact with robot only use arm movement [54].
During the interactions, it is obvious to notice that robot need more advanced behaviors to be developed and the scenario should have more control for data analysis and get more convincing results. Also the functioning level become another important element that need to be considered.
\subsubsection{Expression/Emotion Recognition and Imitation}
Another import difficulty of individuals with ASD is to recognize the expressions and emotions, besides appropriately imitating them. Studies show that kids with ASD have a hard time recognizing emotions and facial expressions. It would be difficult for them to deliver their emotions through their faces actions. Researchers pointed out that to kids with ASD, such emotion type information which contained faces or eye contact can result overwhelming or sensory overload. For example, a person could smile twice, and the child with ASD might pick two entire different expressions from those two smiles. Robot can provide more constancy repeatable consistent behaviors than human does, and it would be a better way to teach children expressions and emotions.
KASPAR, a child-sized doll like robot which has a silicon-rubber face on it, developed by the University of Hertfordshire has been used to show bodily expressions by move head and arms. KASPAR was operated via wireless remotely, sessions are designed to allow the children to have free play interaction with robot. Some behaviors had been pre-programmed in the robot, those behaviors allows KASPAR to show several facial expressions, hand waving and drumming on the tambourine on its legs to express different emotions. During the interaction, three types of touch using the hands had been identified: grasping (different tension levels), stroking, and poking. The forces of touching can be detected by the tactile sensors equipped different places of KASPAR’s arms, hands, face, and shoulders. By detecting different levels of touching, KASPAR would provide different movements or expression to tell the children the emotions or feeling of it. Emotion and facial expressions recognition could be taught via these outputs KASPAR given. The limitation of this study is very few numbers of children (five children in total) had participated in this study. Besides limited facial expressions (happiness, displeasure, surprise etc.) have employed in the robot system, and those expressions are hard to distinguish by the images they provided. There is no verbal communication between kids and robot, which is another weakness of this study [57]. FACE is a robot designed at the University of Pisa point to closely approximate a real human face and show the detail facial expressions. Children would be asked to imitate those expressions to practice their ability in facial expression recognition and imitation. Certain scenarios (i.e. 1) facial expression association: a) facial matching, b) emotion labeling; 2) emotion contextualization) would be given to kids and ask them to pick up an appropriate emotional expression for FACE to make. Several experiments have been implemented to help the children to generalize the information they learn from the therapy sessions. After practicing with FACE, the children were tested using the Childhood Autism Rating Scale and the results showed that while working with FACE, the ability of categories emotions and expressions for all kids (total number of 4 kids) have been improved. Also, researchers found out that those children can imitate facial expressions from FACE better than from humans, and it will be easier for therapist because of the automate repeatable of robots process. However, still very limited number of kids participated in the study that made the results somehow not quite untenable [59].
\subsubsection{Joint/ Eye-gaze Attention}
One of the major deficiencies of individuals with ASD is the lack of continuous concentration on the same object [33]. Joint attention is a concept of remain focus on specific things. Helping children with ASD on this aspect, would also help them to achieve the success in learning other skills. Keep practicing joint attention would give them more understandings of what others are aware of them, what they are aware of other and they both aware of same object.
For this purpose, researchers from National Institute of Information and Communications Technology in Japan developed the Keepon robot. For seeking the possible responses of using interpersonal communication, both ASD and TD kids have been recruited in the study. A silicon-rubber made yellow snowman like body covered above the mechanical parts of Keepon, with two eyes on the upper part of the robot, and a nose (microphone embedded) in between. Lower part which is the belly of Keepon can easily deform whenever it changes posture and when people touch it [58].
With four degrees of freedom (±40 degrees of nodding, ±180 degrees of shaking, ±25 degrees of rocking, and bobbing with 15 mm stroke), Keepon is able to perform two action mode: Attentive action and Emotive action. In attentive mode, Keepon will orient its face/body to a certain object around it, two CCD cameras in its eyes would be able to making eye contact and joint attention with the target; in emotive mode, Keepon will still its attention in a certain direction, and rocks its body up and down or left and right to express its emotions like pleasure and excitement. In both modes, Keepon will also making little sounds to drag the attention of people around it or give some feedback when people touches it or grabs it [58]. 
There are two operation mode to control Keepon, either automatic mode or manual mode. In automation mode, locations of a human face, a toy with a predetermined color, and an optically moving region would be detected. An Attention Map are written inside of Keepon, it orients its body (eye gaze) to most salient point on the Attention Map; its emotional expression is determined by the type (face/toy/motion) and the saliency value of the point of interest. In manual mode, based on the onboard cameras and listens to the sounds captured by the onboard microphone, a person can easily control Keepon via a remote computer. The operator only need to click the interest on the panoramic map to displays emotional expression on Keepon [58].
After more than a year and half (over 500 child-sessions), this research provides some interesting results. Children who have autism and PDD, they usually have difficulty with communicating with others, which however were able to approach Keepon with security and curiosity, and had a good time with it. Some of the kids even learned how to share their pleasure with other people which extended the dyadic interaction to triadic interaction. Different children have different style with communicating with Keepon, based on those different reactions researchers might predict different personality of those children [58].
This study shows some promising conclusions, but still cannot provide statistic results to readers. Overall, the experiment settings have been considerate be thoughtful, though the sessions kept in free play mode. Good amount of partisans enrolled in the study, which makes the conclusion more convincible. The aim of the study has been fully illustrated during sessions, joint attention has ran through both action modes and provided a good feedback from the partisans. Keepon’s voice needs to be improved, not just making simple noise, but also have a complete conversation would be better. More statistic results needs to be analyzed in the future to compare both children with ASD and TD kids.
\subsection{Using NAO in Autism}
NAO is a multifunctional humanoid robot that was developed by Aldebaran Robotics and as it has capabilities such as making different gesture, moving different arm and leg movement and hear orientations, It has been used for different human-robot interaction sessions. In this section we will talk about the existing interactions sessions that were conducted by NAO and later in the next chapter we will explain about our therapy sessions and designed game based on NAO for children with ASD.
In University of Teknologi MARA, NAO was used to conduct seven interactions modules for interacting kids with autism. Each module lasts four minutes, and one minute break was provided between two sessions. Different interaction tasks have been contained in those modules (i.e. static interaction, joint attention, basic language skills). Frequency of child looking at robot and duration of each occurrence of interaction has been reported. After all, they concluded that those 7 modules can be applied to develop human-robot integration therapy sessions for children with autism [80]. Same year, these researchers use 5 of those 7 modules did a case study, with the same setting, they recruited one high-functioning (with IQ 107) to complete those 5 tasks. They aimed to discover whether that child can provide a better exposure behavior with robot compared with the activity in the class. After running the five tasks for only one instance, they concluded that the child behavior have been improved significantly with robot than in the class, they also suggested that humanoid robot NAO can be used as a major platform to support and initiate interaction with children with ASD [81]. After this case study, they recruited other 5 children with ASD (low IQ, average around 50) and did the same experimental interaction sessions with them. For out of five children showed better performance during robot interaction compared with daily in-class performance [82]. Further research have been done by this group, they added emotion recognition module into the interaction sessions. Five body gesture emotions (hungry, happy, mad, scared, and hug/love) have been implemented in the program. Two boys have been enrolled in this study, and after finished the session, researchers pointed out that NAO has the potential capability to teach head and bod posture related to social emotions for children with autism, without provided any statistical analysis only based on observations [83]. This group has been initiated working with NAO for autism therapeutic session and implementing and compared different scenarios based on NAO. Reviewing the existing papers demonstrate that the number of participants and interaction sessions for these studies are very limited. They have used only one session for each subject. Therefore they could not analyze the social responses of individuals with ASD statistically.
In our study we employ NAO since it has several functionalities that are embedded in it (e.g. text-to-speech, tactical sensor, face recognition, voice recognition etc.). This would help us to build a social communicative tasks for human-robot interaction. Based on the size of the robot and the friendly appearance of the robot we design, conduct and analyze the gaze related responses of ASD individual and compare it with TD control group. The details of our experiment and the results will be discussed in Chapter 4.


\section{Emotion Classification}

\subsection{Electrodermal activity (EDA)}
Emotion is an intense mental experience often manifested by rapid heartbeat, breathing, 
sweating, and facial expressions. Emotion recognition from these physiological signals 
is a challenging problem with interesting applications such as developing wearable 
assistive devices and smart human-computer interfaces. This paper presents an automated 
method for emotion classification in children using electrodermal activity (EDA) signals. 
The time-frequency analysis of the acquired raw EDAs provides a feature space based on 
which different emotions can be recognized. To this end, the complex Morlet (C-Morlet) 
wavelet function is applied on the recorded EDA signals. The database used in this paper 
includes a set of multimodal recordings of social and communicative behavior as well 
as EDA recordings of 100 children younger than 30 months old. The dataset is annotated 
by two experts to extract the time sequence corresponding to three main emotions 
including “Joy”, “Boredom”, and “Acceptance”. The annotation process is performed 
considering the synchronicity between the children's facial expressions and the EDA 
time sequences. Various experiments are conducted on the annotated EDA signals to 
classify emotions using a support vector machine (SVM) classifier. The quantitative 
results show that the emotion classification performance remarkably improves compared 
to other methods when the proposed wavelet-based features are used.\\

EDA has been used as an effective and reproducible electrophysiological method for 
investigating sympathetic nervous system function \cite{WearableDevice2016, AssociationBetween2013, SympatheticSkin1984, PrincipalComponent2000}. Note that the sympathetic nervous 
burst changes the skin conductance, which can be traced by analyzing the EDA signals\cite{SkinConduct2006, SympatheticSkin1981, DecodeChild2013}. The Q-sensor 
is a convenient wireless-based EDA device with no need for cables, boxes, or skin 
preparation. This device can track three types of data including EDA, temperature, 
and acceleration at the same time \cite{Validation2013}. It is worth mentioning that 
as of today, there has been no published work on emotion classification using the 
EDA signals collected by this dataset collected at the Georgia Institute of 
Technology \cite{DecodeChild2013}.\\

EDA signals are nonstationary and noisy; hence, wavelet-based analysis of EDA signals 
has been considered in the literature \cite{EmotionalState2013, EMGGSR2009}
either as a pre-processing step or a feature extraction approach for emotion classification. 
\cite{EmotionalState2013} used a set of wavelet coefficients representing EDA features 
together with heart rate signal to increase the percentage of correct classifications 
of emotional states and provide clearer relationships among the physiological response 
and arousal and valence. \cite{EDA2016} used a feature space based on the 
discrete wavelet transform (DWT) of the EDA signal to distinguish subjects suffering 
social anxiety disorder (SAD) and a control group. Using MLP and DWT features, they 
achieved a classification accuracy of ~85%.\\

\subsection{Classification Applications}
Physiological responses have been identified as reliable indicators of human emotional 
and cognitive states. This section is dedicated to review some existing methods used for 
human emotion recognition based on various physiological responses, such as facial 
expression and other types of bio-signals. \\

A wearable glass device was designed by \cite{WearableDevice2016} to measure both electrodermal 
activity (EDA) and photoplethysmogram data for emotion recognition purposes. A built-in 
camera was also used in this device for capturing partial facial expression from the eye 
and nose area. This approach obtains remarkable performance in facial expression 
recognition in the subject-dependent cases. However, for subject-independent cases, 
it results in different accuracies across different types of emotions, which is an 
undesirable feature. \\

Several emotion classification methods have been presented in the literature using 
different bio-signals \cite{EmotionInten2014, EmotionResp2013, ElectAct2000, HeteroKnow2016}. Due to the variety of the signals used in these methods, 
different approaches have been designed to comply with their specific characteristics. 
Analysis of variance (ANOVA) and linear regression \cite{ElectAct2000} are the 
commonly used methods to extract features from bio-signals and to recognize different 
emotional states. These methods are based on the assumption of a linear relationship 
between the recorded signals and emotional states. A fuzzy-based classification 
method \cite{EmotionInten2014} has been used in to transform EDA and facial 
electromyography (EMG) to valence and arousal states. These states were then used 
to classify different emotions. \\

Artificial neural networks (ANN) have also been applied for emotion classification 
tasks based on physiological responses. \cite{MultPercep2007} developed a multilayer perceptron 
network (MLP) architecture capable of recognizing five emotions using various features 
from Electrocardiography (ECG) and EDA signals, and obtained very accurate classification 
performance. \cite{EmotionRecog2004} employed K-nearest neighborhood and discriminant 
function analysis to perform the emotion classification task using different features 
extracted from the EDA signals, body temperature and heart rate.\\

Support Vector Machine (SVM) is a well-known supervised learning algorithm that has 
extensively been used for pattern classification and regression \cite{SupportVector1995}. The SVM classifier tends to separate dataset by drawing an optimal hyperplane 
between classes such that the margin between them becomes maximum. The samples of 
each class that are located within the margin are called support vectors and play the 
main role in calculating the parameters of the hyperplanes between the corresponding 
classes. Machine learning algorithms such as SVM, linear discriminant analysis (LDA), 
and classification and regression tree (CART) have been employed for emotion 
classification purposes. For instance, in several works including \cite{Taxonomy2011, EmotionClassifi2014}, the authors combined various types of bio-signals such as ECG, 
skin temperature (SKT), HR, and Photoplethysmogram (PPG) for  emotion classification 
purposes. \cite{FeatureSelection2006} proposed unsupervised clustering methods for emotion 
recognition. Their method benefited from several features obtained from different 
body responses such as SC, HR, and EMG. They showed that only a few statistical 
features such as the mean and standard deviation of the data can be relevant identifiers 
for defining different clusters. \\

To the best of our knowledge there are a few works \cite{EmotionResp2013, SlowEcho2009} that have studied and compared different automated 
classification techniques for emotion recognition of children using EDA signals. 
This motivated us to conduct this study using an existing dataset, which concentrates 
on emotion classification of children based on the relationship between their facial 
expressions and the collected EDA signals.

\section{Music Therapy}

Music is effective method to involve children with autism in rhythmic and non-verbal
communication. Besides, music has often been used in therapeutic sessions with children who have suffer from mental and behavioral
disabilities \cite{roper2003melodic, boso2007effect}. Nowadays, at least 12\% of all treatment of individuals with autism consist
of music-based therapies \cite{bhat2013review}. Specifically, teaching and playing music to children
with autism spectrum disorders (ASD) in therapy sessions have shown great impact for improving social communication
skills \cite{lim2011effects}. Recorded music or human played back music are used in single and multiple subjects'
intervention session from many studies \cite{bhat2013review, corbett2008brief}. Different social skills are targeted and reported
(i.e. eye-gaze attention, joint attention and turn-taking activities) in using music-based therapy sessions 
\cite{stephens2008spontaneous, kim2008effects}. Noted that improving gross and fine motor skills for ASD
through music interventions is a missing part in this field of studies \cite{bhat2013review}.

Socially assistive robots are widely used in young age of autism population interventions these years. Some studies are
focusing on eye contact and joint attention \cite{feng2013can, mihalache2020perceiving, mavadati2014comparing}, 
showing that at some point the pattern of ASD group in perceiving eye gaze are similar to typically 
developed (TD) kid, and eye contact skills can be significantly improved after intervention sessions. Plus,
these findings also provides a strong evidence of ASD kids are easy to attracted to humanoid robots in
various type of social activities. Some groups start to use such robots to conduct music-based therapy
sessions nowadays. Children with autism are asked to imitate play music based on Wizard of Oz style
and Applied Behavior Analysis (ABA) models from humanoid robots in intervention sessions for practicing
eye-gaze and joint attention skills \cite{peng2014using, taheri2015impact, taheri2016social}. However, 
some disadvantages of such research due to lack of sample size and no automated system in human-robot 
interaction. Music can be used as unique window into the world of autism, lots of evidence suggest that
many individuals with ASD are able to understand simple and complex emotions in childhood using music-based
therapy sessions \cite{molnar2012music}. Although limited research has found in such area especially using
bio-signals for emotion recognition for ASD and TD kids \cite{feng2018wavelet} in understanding the 
relationship between activities and emotion changes. 

To this end, in current research a automated music-based social robot platform with activity-based emotion 
recognition system is presented in the following sections. The purpose of this platform is to provide a 
possible ultimate solution for assisting children with autism to improve motor skills, turn-taking skills 
and activity engagement initiation. Further more, by using bio-signals with Complex-Morlet (C-Morlet) wavelet feature 
extraction \cite{feng2018wavelet}, emotion classification and emotion fluctuation are analyzed based on different 
activities. TD kids are participated as control group in order to see the difference from ASD group.\\





