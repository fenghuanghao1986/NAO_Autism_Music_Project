\chapter{Acoustic Music Teaching Experiment Design Data Acquisition and Result}
A few questions will be answered in terms of social skills in this chapter:
1) Turn Taking: How well kids with autism behave during the teaching and learning
process as compared to the TD group, e.g., kid listens to the instruction or demonstration 
from the robot before he/she plays the instrument;
2) Joint Attention and Eye-Gaze Attention: How well kids with ASD follow instructions 
and adapt hints as compared to TD kids, e.g., kid follows hitting positions demonstrated 
by the robot or follows the change of eye colors;
3) Motor Control: How well ASD kids play the xylophone in terms of volume, pitch and
accuracy compared to the TD group, e.g., a good multiple strikes should be recognized by 
STFT as a sequence of frequencies (design in previous chapter);
4) Engagement and Event Based Emotion: How kids engage with different music teaching
events and what emotions are displayed during these events, e.g., using EDA signal to
find out the emotions regarding different situations such as having a hard time
memorizing a sequence of notes;
5) Facial Expression and Emotions Correlation: (will not be presented in this version);
6) Music Emotions and Feelings: How kids perceive emotions in small pieces of music 
within different melodies, e.g., music in different keys.\\

\section{Room Setup and Participants}
Figure \ref{room} shows the schematic of therapy session and video capturing setting.
Figure \ref{room_pana} shows the actual room.
\begin{figure}[tbp]
	\begin{center}
		\begin{tabular}{c}
			\epsfig{figure=./chapters/fig/room.eps, scale = .6}\label{room} \\
		\end{tabular}
		\caption{Schematic robot-based therapy session and video capturing setting} \label{room}
	\end{center}
\end{figure}

\begin{figure}[tbp]
	\begin{center}
		\begin{tabular}{c}
			\epsfig{figure=./chapters/fig/room_pana.eps, scale = .22}\label{room_pana} \\
		\end{tabular}
		\caption{Experiment Room Setup} \label{room_pana}
	\end{center}
\end{figure}

\section{Experiment Design}
In order to collect all the data for answering the questions above, a set of
intervention sessions were designed using music therapy concepts. 6 - 7 sessions
were created for the ASD group and 2 sessions for the TD group. For the ASD group, entire
sessions were divided into 3 parts: baseline session, intervention sessions
and exit session. Similar to the ASD group, the TD group only includes a baseline session
and an exit session for comparison purposes. In addition, a social music
game play was also included in each session for system testing and entertainment
purposes.\\

\subparagraph{Baseline Session: }Participants were asked to follow all the 
instructions contained in all the practices from the following intervention session 
including single bar strike, multiple bars strike, half song play and the whole
song play. We choose a very popular kid's song "Twinkle Twinkle Little Star" 
for this specific session due to how well-known this song is in almost 
everyone's childhood.\\

\subparagraph{Intervention Sessions: }These sessions are assigned to ASD group
particularly and include single strike with color hints, multiple strikes with
colors hint, half-song practice and whole song practice. In this part, a special
participant-selected song will be used through the rest of the sessions. In the second
half of this intervention session set, single/multiple strikes were also covered
before the half/full song practice in order to have participants use the
color matching technique during the high level music play due to a lack of professional
music background knowledge. In addition, starting from session 2, a single strike
warm up practice was added before the formal music practice starts. This particular
practice was designed to have better motor control for ASD group, so that
the robot is able to recognize notes properly and deliver the concept in telling the
difference between "making a sound" and "playing a musical note". \\

\subparagraph{Exit Session: }Both groups were assigned to go through the same steps
as the baseline session in choice of their own songs. We would like to see the 
difference between two groups in learning a beloved song by their own.\\

Due to the difficulty of user selected songs and different performance scores of
participants, the total session numbers can be various: 6 visits will be the minimum
requirement for ASD group with the total number of visits not going beyond 8 times. More detailed 
experiment design is shown in the table below:\\

% still working on this table design
% show all experiment setup table here
%\begin{table}
%	\begin{center}
%		\caption{Performance Comparison Between the Two Methods and the
%			Manually Labeled Features Based on the Average MSE (pixels) Over All
%			70 Subjects.}
%		\begin{tabular}{|c|c|c|c|}
%			\hline
%			Method&Ave.MSE &Ave. MSE&\% of cases\\
%			&for 49 subjects&for 21 subjects&which have\\
%			&out of 70&out of 70&minimum error\\
%			\hline
%			Standard&&&\\
%			ASM & 70.3 (pixels)& 23.3 (pixels)& 30.0\% \\
%			\hline
%			Enhanced&&&\\
%			ASM & 40.0 (pixels)& 31.9 (pixels)& 70.0\% \\
%			\hline
%		\end{tabular}
%		\\
%		\label{table_2}
%	\end{center}
%\end{table}

\section{Methodology and Experiment Result}

\subsection{Social Aspects Annotation and Coding Methods}
This part is to describe how to do video coding in these social features.
Basically just post process by watching the front face videos and by listen to the
audio to code how the social behaviors been performed. Have to copy some of the stuff
from previous studies.
%\subparagraph{Turn-Taking Coding}
%\subparagraph{Joint Attention Coding}

\subsection{Motor Control Scoring System}
This is related to hitting practice and play practice in real time during the session.
Need to have connections with the module 2 real time performance scoring feedback system.
Describe the how the flow goes during the session and how to have small add on dosage
if the accuracy not good. \\

Also have to make up a story when it goes to the half/whole song, how to manage that
if the kid cannot play well, just cut the whole chunk into small continuous pieces
and use the same methods and scoring system to deliver the idea. \\


\begin{tabular}{ | c | c | c | c | c |  }
	\hline
	& Baseline & Exit & Inter 2 & Inter 3 \\ \hline
	TD001 & $~20\%$ & $~40\%$ & N/A & N/A \\ \hline
	TD002 & $~30\%$ & $~70\%$ & N/A & N/A \\ \hline
	TD004 & $~30\%$ & $~60\%$ & N/A & N/A \\ \hline
	ASD101 & $~20\%$ & N/A & $~80\%$ & $~90\%$ \\ \hline
\end{tabular}\newline

\subsection{Emotion Classification}
Since we developed our emotion classification method based on the time-frequency analysis of the
EDA signals, the main properties of the continuous wavelet transform assuming complex Morlet
wavelet is first presented here. Then, the pre-processing steps, as well as the wavelet-based
feature extraction scheme, are discussed. Finally, we briefly review the characteristics of the
support vector machine as the classifier used with our approach.\\

%\subsection{Dialog System}
%
%\subsubsection{Speech Recognition}
%http://doc.aldebaran.com/2-1/naoqi/audio/alspeechrecognition.html
%
%\subsubsection{Dynamic Oral Feedback}
%reason to design the dynamic feedback. 
