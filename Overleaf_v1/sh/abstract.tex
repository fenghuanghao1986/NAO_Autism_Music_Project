\newpage
\pagestyle{empty}
\renewcommand{\baselinestretch}{1}
\begin{flushleft}
\small {
FENG, HUANGHAO  \hfill (M.S., Electrical and Computer Engineering)\\
\underline{} \hfill (\mydate)\\
\underline{}}

\vspace{0.25in}
Abstract of a dissertation at the University of Denver.\\
\vspace{0.25in}
Dissertation supervised by Dr. Mohammad Mahoor.\\
No. of pages in text \underline{\pageref{LastPage}}.
\end{flushleft}
\renewcommand{\baselinestretch}{2}
\normalsize{Children with Autism Spectrum Disorder (ASD) experience deficits in verbal and nonverbal communication skills, including motor control, emotional facial expressions, and eye gaze / joint attention. This Ph.D. dissertation focuses on studying the feasibility and effectiveness of using a social robot, called NAO, and a toy music instrument, xylophone, at modeling and improving the social responses and behaviors of children with ASD. In our investigation, we designed an autonomous social interactive music teaching system to fulfill this mission.
A novel modular robot-music teaching system consisting of three modules is presented. Module 1 provides an autonomous self-awareness positioning system for the robot to localize the instrument and make a micro adjustment for the arm joints to play the note bars properly. Module 2 allows the robot to be able to play any customized song per user’s request. This design provides an opportunity to translate songs into C-major or a-minor with a set of hexadecimal numbers, allowing a person who has less music experience to complete this work. After the music score converted robot should be able to play it immediately. Module 3 is designed for providing real-life music teaching experience for the users. Two key features of this module are a) "music detection" and b) "smart scoring and feedback". Short-time Fourier transform and Levenshtein distance are adapted to fulfill the design requirements, which allow the robot to understand music and provide a proper dosage of practice and oral feedback to users. A new instrument has designed to present better emotions from music due to the limitation of the original xylophone. This new programmable xylophone can provide a more extensive frequency range of notes, easily switch between the Major and Minor keys, extensively easy to control, and have fun with it as an advanced music instrument. 

Because our initial intention has been to study emotion in children with autism, an automated method for emotion classification in children using electrodermal activity (EDA) signals. The time-frequency analysis of the acquired raw EDAs provides a feature space based on which different emotions can be recognized. To this end, the complex Morlet (C-Morlet) wavelet function is applied to the recorded EDA signals. The dataset used in this research includes a set of multimodal recordings of social and communicative behavior as well as EDA recordings of 100 children younger than 30 months old. The dataset is annotated by two experts to extract the time sequence corresponding to three primary emotions, including “Joy”, “Boredom”, and “Acceptance”. Various experiments are conducted on the annotated EDA signals to classify emotions using a support vector machine (SVM) classifier. The quantitative results show that emotion classification performance remarkably improves compared to other methods when the proposed wavelet-based features are used. By using this emotion classification, emotion engagement during sessions, and feelings between different music can be detected after data analysis.

NAO music education platform will be thought-about as a decent tool to facilitate improving fine motor control, turn-taking skills, and social activities engagement. Most of the ASD youngsters began to develop the strike movement when initial 2 intervention sessions; some even will master the motor ability throughout the early events. More than half of the subjects could dominate proper turn-taking after few sessions. Music teaching could be a good example for accomplishing social skill tasks by taking advantage of customized songs selected by individuals. According to the session executioner and video annotators, this particular subject shows a high level of engagement for all activities, including free play. Based on the conversation and music performance with the robot, the subject showed a strong interest in challenging the robot in a friendly way.\\

}
